`torch_dtype` is deprecated! Use `dtype` instead!
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
âœ… CUDA available: NVIDIA GeForce RTX 3050 Laptop GPU
   Total VRAM: 4.08 GB
============================================================
ðŸš€ QLoRA FINE-TUNING EXPERIMENT
============================================================
Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Dataset: dataset_sharegpt_curated.json
Output: output/v2.4-recovery-4ep
Epochs: 4
Batch size: 1
Gradient accumulation: 4
Effective batch size: 4
Learning rate: 0.0002
LoRA r=16, alpha=32
============================================================

ðŸ“‚ Loading dataset...
âœ… Loaded 153 examples
ðŸ“¦ Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]Loading weights:   0%|          | 1/201 [00:00<00:00, 4865.78it/s, Materializing param=lm_head.weight]Loading weights:   0%|          | 1/201 [00:00<00:00, 2621.44it/s, Materializing param=lm_head.weight]Loading weights:   1%|          | 2/201 [00:00<00:00, 2440.68it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|          | 2/201 [00:00<00:00, 2181.69it/s, Materializing param=model.embed_tokens.weight]Loading weights:   1%|â–         | 3/201 [00:00<00:00, 2708.92it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   1%|â–         | 3/201 [00:00<00:00, 2542.00it/s, Materializing param=model.layers.0.input_layernorm.weight]Loading weights:   2%|â–         | 4/201 [00:00<00:00, 3044.31it/s, Materializing param=model.layers.0.mlp.down_proj.weight]  Loading weights:   2%|â–         | 4/201 [00:00<00:00, 2922.35it/s, Materializing param=model.layers.0.mlp.down_proj.weight]Loading weights:   2%|â–         | 5/201 [00:00<00:03, 57.55it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]  Loading weights:   2%|â–         | 5/201 [00:00<00:03, 57.47it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   3%|â–Ž         | 6/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.mlp.gate_proj.weight]Loading weights:   3%|â–Ž         | 6/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.mlp.up_proj.weight]  Loading weights:   3%|â–Ž         | 6/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.mlp.up_proj.weight]Loading weights:   3%|â–Ž         | 7/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   3%|â–Ž         | 7/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.post_attention_layernorm.weight]Loading weights:   4%|â–         | 8/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]        Loading weights:   4%|â–         | 8/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.k_proj.weight]Loading weights:   4%|â–         | 9/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   4%|â–         | 9/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.o_proj.weight]Loading weights:   5%|â–         | 10/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   5%|â–         | 10/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.q_proj.weight]Loading weights:   5%|â–Œ         | 11/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   5%|â–Œ         | 11/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.0.self_attn.v_proj.weight]Loading weights:   6%|â–Œ         | 12/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.1.input_layernorm.weight] Loading weights:   6%|â–Œ         | 12/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.1.input_layernorm.weight]Loading weights:   6%|â–‹         | 13/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.1.mlp.down_proj.weight]  Loading weights:   6%|â–‹         | 13/201 [00:00<00:03, 58.15it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   7%|â–‹         | 14/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.mlp.down_proj.weight]Loading weights:   7%|â–‹         | 14/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   7%|â–‹         | 14/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.mlp.gate_proj.weight]Loading weights:   7%|â–‹         | 15/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.mlp.up_proj.weight]  Loading weights:   7%|â–‹         | 15/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.mlp.up_proj.weight]Loading weights:   8%|â–Š         | 16/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   8%|â–Š         | 16/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.post_attention_layernorm.weight]Loading weights:   8%|â–Š         | 17/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]        Loading weights:   8%|â–Š         | 17/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.k_proj.weight]Loading weights:   9%|â–‰         | 18/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   9%|â–‰         | 18/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.o_proj.weight]Loading weights:   9%|â–‰         | 19/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:   9%|â–‰         | 19/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.q_proj.weight]Loading weights:  10%|â–‰         | 20/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:  10%|â–‰         | 20/201 [00:00<00:02, 66.61it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:  10%|â–ˆ         | 21/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.1.self_attn.v_proj.weight]Loading weights:  10%|â–ˆ         | 21/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.input_layernorm.weight] Loading weights:  10%|â–ˆ         | 21/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.input_layernorm.weight]Loading weights:  11%|â–ˆ         | 22/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.down_proj.weight]  Loading weights:  11%|â–ˆ         | 22/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.down_proj.weight]Loading weights:  11%|â–ˆâ–        | 23/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:  11%|â–ˆâ–        | 23/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.gate_proj.weight]Loading weights:  12%|â–ˆâ–        | 24/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.up_proj.weight]  Loading weights:  12%|â–ˆâ–        | 24/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.mlp.up_proj.weight]Loading weights:  12%|â–ˆâ–        | 25/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:  12%|â–ˆâ–        | 25/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.post_attention_layernorm.weight]Loading weights:  13%|â–ˆâ–Ž        | 26/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]        Loading weights:  13%|â–ˆâ–Ž        | 26/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.k_proj.weight]Loading weights:  13%|â–ˆâ–Ž        | 27/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  13%|â–ˆâ–Ž        | 27/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.o_proj.weight]Loading weights:  14%|â–ˆâ–        | 28/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  14%|â–ˆâ–        | 28/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.q_proj.weight]Loading weights:  14%|â–ˆâ–        | 29/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  14%|â–ˆâ–        | 29/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.2.self_attn.v_proj.weight]Loading weights:  15%|â–ˆâ–        | 30/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.input_layernorm.weight] Loading weights:  15%|â–ˆâ–        | 30/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.input_layernorm.weight]Loading weights:  15%|â–ˆâ–Œ        | 31/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.down_proj.weight]  Loading weights:  15%|â–ˆâ–Œ        | 31/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.down_proj.weight]Loading weights:  16%|â–ˆâ–Œ        | 32/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  16%|â–ˆâ–Œ        | 32/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.gate_proj.weight]Loading weights:  16%|â–ˆâ–‹        | 33/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.up_proj.weight]  Loading weights:  16%|â–ˆâ–‹        | 33/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.mlp.up_proj.weight]Loading weights:  17%|â–ˆâ–‹        | 34/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  17%|â–ˆâ–‹        | 34/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.post_attention_layernorm.weight]Loading weights:  17%|â–ˆâ–‹        | 35/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]        Loading weights:  17%|â–ˆâ–‹        | 35/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.k_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 36/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 36/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.o_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 37/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  18%|â–ˆâ–Š        | 37/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.q_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 38/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 38/201 [00:00<00:04, 40.58it/s, Materializing param=model.layers.3.self_attn.v_proj.weight]Loading weights:  19%|â–ˆâ–‰        | 39/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.input_layernorm.weight] Loading weights:  19%|â–ˆâ–‰        | 39/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.input_layernorm.weight]Loading weights:  20%|â–ˆâ–‰        | 40/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.down_proj.weight]  Loading weights:  20%|â–ˆâ–‰        | 40/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.down_proj.weight]Loading weights:  20%|â–ˆâ–ˆ        | 41/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  20%|â–ˆâ–ˆ        | 41/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.gate_proj.weight]Loading weights:  21%|â–ˆâ–ˆ        | 42/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.up_proj.weight]  Loading weights:  21%|â–ˆâ–ˆ        | 42/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.mlp.up_proj.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 43/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 43/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.post_attention_layernorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 44/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]        Loading weights:  22%|â–ˆâ–ˆâ–       | 44/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.k_proj.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 45/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 45/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.o_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 46/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.q_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 47/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 47/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.4.self_attn.v_proj.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 48/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.input_layernorm.weight] Loading weights:  24%|â–ˆâ–ˆâ–       | 48/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.input_layernorm.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 49/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.down_proj.weight]  Loading weights:  24%|â–ˆâ–ˆâ–       | 49/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.down_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–       | 50/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–       | 50/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.gate_proj.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 51/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.up_proj.weight]  Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 51/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.mlp.up_proj.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 52/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 52/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.post_attention_layernorm.weight]Loading weights:  26%|â–ˆâ–ˆâ–‹       | 53/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]        Loading weights:  26%|â–ˆâ–ˆâ–‹       | 53/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.k_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 54/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 54/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.o_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 55/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 55/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.q_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 56/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 56/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.5.self_attn.v_proj.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 57/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.input_layernorm.weight] Loading weights:  28%|â–ˆâ–ˆâ–Š       | 57/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.input_layernorm.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 58/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.down_proj.weight]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 58/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.down_proj.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 59/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 59/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.gate_proj.weight]Loading weights:  30%|â–ˆâ–ˆâ–‰       | 60/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.up_proj.weight]  Loading weights:  30%|â–ˆâ–ˆâ–‰       | 60/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.mlp.up_proj.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 61/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 61/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.post_attention_layernorm.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 62/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]        Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 62/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.k_proj.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆâ–      | 63/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆâ–      | 63/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.o_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 64/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.q_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 65/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 65/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.6.self_attn.v_proj.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.input_layernorm.weight] Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.input_layernorm.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.down_proj.weight]  Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.down_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 68/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.gate_proj.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.up_proj.weight]  Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 69/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.mlp.up_proj.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 70/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 70/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.post_attention_layernorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]        Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.k_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.o_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.q_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.7.self_attn.v_proj.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 75/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.input_layernorm.weight] Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 75/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.input_layernorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.down_proj.weight]  Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.down_proj.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.gate_proj.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.up_proj.weight]  Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.mlp.up_proj.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 79/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 79/201 [00:00<00:03, 40.58it/s, Materializing param=model.layers.8.post_attention_layernorm.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 80/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]        Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 80/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.k_proj.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.o_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.q_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.8.self_attn.v_proj.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.input_layernorm.weight] Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.input_layernorm.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.down_proj.weight]  Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 85/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.down_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.gate_proj.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.up_proj.weight]  Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.mlp.up_proj.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.post_attention_layernorm.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]        Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.k_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.o_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.q_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.9.self_attn.v_proj.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.input_layernorm.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.down_proj.weight]  Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.down_proj.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 95/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 95/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.gate_proj.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.up_proj.weight]  Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.mlp.up_proj.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.post_attention_layernorm.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]        Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.k_proj.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.o_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 100/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.q_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.10.self_attn.v_proj.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.input_layernorm.weight] Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.input_layernorm.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 103/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.down_proj.weight]  Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 103/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.down_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.gate_proj.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.up_proj.weight]  Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.mlp.up_proj.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.post_attention_layernorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]        Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.k_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 108/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.o_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.q_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 110/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.11.self_attn.v_proj.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.input_layernorm.weight] Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.input_layernorm.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.down_proj.weight]  Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.down_proj.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 113/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.gate_proj.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.up_proj.weight]  Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.mlp.up_proj.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 115/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.post_attention_layernorm.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]        Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.k_proj.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.o_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 118/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.q_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/201 [00:00<00:02, 40.58it/s, Materializing param=model.layers.12.self_attn.v_proj.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 120/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.input_layernorm.weight] Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 120/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.input_layernorm.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.down_proj.weight]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.down_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.gate_proj.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 123/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.up_proj.weight]  Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 123/201 [00:00<00:01, 40.58it/s, Materializing param=model.layers.13.mlp.up_proj.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.mlp.up_proj.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.post_attention_layernorm.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]        Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.k_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.o_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.q_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 128/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 128/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.13.self_attn.v_proj.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.input_layernorm.weight] Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.input_layernorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.down_proj.weight]  Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 130/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.down_proj.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.gate_proj.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.up_proj.weight]  Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.mlp.up_proj.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 133/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 133/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.post_attention_layernorm.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]        Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.k_proj.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 135/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 135/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.o_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.q_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.14.self_attn.v_proj.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 138/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.input_layernorm.weight] Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 138/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.input_layernorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.down_proj.weight]  Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.down_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 140/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 140/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.gate_proj.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.up_proj.weight]  Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.mlp.up_proj.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.post_attention_layernorm.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 143/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]        Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 143/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.k_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.o_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.q_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.15.self_attn.v_proj.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.input_layernorm.weight] Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.input_layernorm.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 148/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.down_proj.weight]  Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 148/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.down_proj.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.gate_proj.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.up_proj.weight]  Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 150/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.mlp.up_proj.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.post_attention_layernorm.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]        Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.k_proj.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 153/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 153/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.o_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.q_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 155/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 155/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.16.self_attn.v_proj.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.input_layernorm.weight] Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.input_layernorm.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.down_proj.weight]  Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.down_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 158/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 158/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.gate_proj.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.up_proj.weight]  Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.mlp.up_proj.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 160/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 160/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.post_attention_layernorm.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]        Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.k_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.o_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 163/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 163/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.q_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.17.self_attn.v_proj.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.input_layernorm.weight] Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.input_layernorm.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.down_proj.weight]  Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.down_proj.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.gate_proj.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 168/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.up_proj.weight]  Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 168/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.mlp.up_proj.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.post_attention_layernorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 170/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]        Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 170/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.k_proj.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.o_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.q_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 173/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 173/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.18.self_attn.v_proj.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.input_layernorm.weight] Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.input_layernorm.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 175/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.down_proj.weight]  Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 175/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.down_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.gate_proj.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.up_proj.weight]  Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.mlp.up_proj.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 178/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 178/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.post_attention_layernorm.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]        Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.k_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 180/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 180/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.o_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.q_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.19.self_attn.v_proj.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 183/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.input_layernorm.weight] Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 183/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.input_layernorm.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.down_proj.weight]  Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.down_proj.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.gate_proj.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.up_proj.weight]  Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.mlp.up_proj.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.post_attention_layernorm.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 188/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]        Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 188/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.k_proj.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.o_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 190/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 190/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.q_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.20.self_attn.v_proj.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.input_layernorm.weight] Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.input_layernorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 193/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.down_proj.weight]  Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 193/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.down_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.gate_proj.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 195/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.up_proj.weight]  Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 195/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.mlp.up_proj.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.post_attention_layernorm.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]        Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.k_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 198/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 198/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.o_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.q_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 200/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 200/201 [00:00<00:00, 309.09it/s, Materializing param=model.layers.21.self_attn.v_proj.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 309.09it/s, Materializing param=model.norm.weight]                      Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 309.09it/s, Materializing param=model.norm.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 324.47it/s, Materializing param=model.norm.weight]
âœ… Model loaded. Memory allocated: 1.04 GB

ðŸ”§ Applying LoRA adapters...
trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079

ðŸ“Š Preprocessing dataset...

ðŸ‹ï¸  Starting training...
VRAM before training: 1.06 GB
  0%|          | 0/156 [00:00<?, ?it/s]  1%|          | 1/156 [00:02<06:57,  2.69s/it]  1%|â–         | 2/156 [00:05<06:27,  2.51s/it]  2%|â–         | 3/156 [00:07<06:19,  2.48s/it]  3%|â–Ž         | 4/156 [00:09<06:14,  2.47s/it]  3%|â–Ž         | 5/156 [00:12<06:14,  2.48s/it]  4%|â–         | 6/156 [00:14<06:14,  2.49s/it]  4%|â–         | 7/156 [00:17<06:12,  2.50s/it]  5%|â–Œ         | 8/156 [00:20<06:10,  2.50s/it]  6%|â–Œ         | 9/156 [00:22<06:07,  2.50s/it]  6%|â–‹         | 10/156 [00:25<06:06,  2.51s/it]                                                  6%|â–‹         | 10/156 [00:25<06:06,  2.51s/it]  7%|â–‹         | 11/156 [00:27<06:02,  2.50s/it]  8%|â–Š         | 12/156 [00:29<05:56,  2.48s/it]  8%|â–Š         | 13/156 [00:32<05:54,  2.48s/it]  9%|â–‰         | 14/156 [00:34<05:48,  2.46s/it] 10%|â–‰         | 15/156 [00:37<05:46,  2.45s/it] 10%|â–ˆ         | 16/156 [00:39<05:43,  2.45s/it] 11%|â–ˆ         | 17/156 [00:42<05:43,  2.47s/it] 12%|â–ˆâ–        | 18/156 [00:44<05:38,  2.45s/it] 12%|â–ˆâ–        | 19/156 [00:47<05:34,  2.44s/it] 13%|â–ˆâ–Ž        | 20/156 [00:49<05:30,  2.43s/it]                                                 13%|â–ˆâ–Ž        | 20/156 [00:49<05:30,  2.43s/it] 13%|â–ˆâ–Ž        | 21/156 [00:51<05:26,  2.42s/it] 14%|â–ˆâ–        | 22/156 [00:54<05:23,  2.42s/it] 15%|â–ˆâ–        | 23/156 [00:56<05:21,  2.42s/it] 15%|â–ˆâ–Œ        | 24/156 [00:59<05:23,  2.45s/it] 16%|â–ˆâ–Œ        | 25/156 [01:01<05:27,  2.50s/it] 17%|â–ˆâ–‹        | 26/156 [01:04<05:22,  2.48s/it] 17%|â–ˆâ–‹        | 27/156 [01:06<05:18,  2.47s/it] 18%|â–ˆâ–Š        | 28/156 [01:09<05:14,  2.46s/it] 19%|â–ˆâ–Š        | 29/156 [01:11<05:11,  2.45s/it] 19%|â–ˆâ–‰        | 30/156 [01:14<05:07,  2.44s/it]                                                 19%|â–ˆâ–‰        | 30/156 [01:14<05:07,  2.44s/it] 20%|â–ˆâ–‰        | 31/156 [01:16<05:04,  2.43s/it] 21%|â–ˆâ–ˆ        | 32/156 [01:18<05:01,  2.43s/it] 21%|â–ˆâ–ˆ        | 33/156 [01:21<04:59,  2.43s/it] 22%|â–ˆâ–ˆâ–       | 34/156 [01:23<04:56,  2.43s/it] 22%|â–ˆâ–ˆâ–       | 35/156 [01:26<04:54,  2.43s/it] 23%|â–ˆâ–ˆâ–Ž       | 36/156 [01:28<04:50,  2.42s/it] 24%|â–ˆâ–ˆâ–Ž       | 37/156 [01:30<04:47,  2.42s/it] 24%|â–ˆâ–ˆâ–       | 38/156 [01:33<04:44,  2.41s/it] 25%|â–ˆâ–ˆâ–Œ       | 39/156 [01:33<03:39,  1.87s/it] 26%|â–ˆâ–ˆâ–Œ       | 40/156 [01:36<04:13,  2.19s/it]                                                 26%|â–ˆâ–ˆâ–Œ       | 40/156 [01:36<04:13,  2.19s/it] 26%|â–ˆâ–ˆâ–‹       | 41/156 [01:39<04:19,  2.25s/it] 27%|â–ˆâ–ˆâ–‹       | 42/156 [01:41<04:21,  2.30s/it] 28%|â–ˆâ–ˆâ–Š       | 43/156 [01:44<04:23,  2.33s/it] 28%|â–ˆâ–ˆâ–Š       | 44/156 [01:46<04:23,  2.35s/it] 29%|â–ˆâ–ˆâ–‰       | 45/156 [01:48<04:22,  2.37s/it] 29%|â–ˆâ–ˆâ–‰       | 46/156 [01:51<04:21,  2.38s/it] 30%|â–ˆâ–ˆâ–ˆ       | 47/156 [01:53<04:20,  2.39s/it] 31%|â–ˆâ–ˆâ–ˆ       | 48/156 [01:56<04:18,  2.40s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 49/156 [01:58<04:17,  2.41s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 50/156 [02:00<04:15,  2.41s/it]                                                 32%|â–ˆâ–ˆâ–ˆâ–      | 50/156 [02:00<04:15,  2.41s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 51/156 [02:03<04:13,  2.42s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/156 [02:05<04:11,  2.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 53/156 [02:08<04:09,  2.42s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 54/156 [02:10<04:08,  2.44s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 55/156 [02:13<04:07,  2.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/156 [02:15<04:05,  2.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 57/156 [02:18<04:02,  2.45s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 58/156 [02:20<03:59,  2.45s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 59/156 [02:23<03:58,  2.46s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/156 [02:25<03:54,  2.45s/it]                                                 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/156 [02:25<03:54,  2.45s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 61/156 [02:27<03:51,  2.44s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 62/156 [02:30<03:48,  2.43s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 63/156 [02:32<03:45,  2.43s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 64/156 [02:35<03:43,  2.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 65/156 [02:37<03:40,  2.43s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/156 [02:40<03:38,  2.43s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 67/156 [02:42<03:35,  2.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/156 [02:44<03:33,  2.43s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69/156 [02:47<03:31,  2.43s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/156 [02:49<03:28,  2.43s/it]                                                 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/156 [02:49<03:28,  2.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 71/156 [02:52<03:26,  2.43s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/156 [02:54<03:23,  2.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 73/156 [02:56<03:21,  2.43s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/156 [02:59<03:18,  2.43s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 75/156 [03:01<03:16,  2.43s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/156 [03:04<03:13,  2.42s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 77/156 [03:06<03:10,  2.42s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 78/156 [03:07<02:26,  1.87s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 79/156 [03:10<02:50,  2.21s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 80/156 [03:12<02:54,  2.30s/it]                                                 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 80/156 [03:12<02:54,  2.30s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/156 [03:15<02:56,  2.36s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 82/156 [03:17<02:57,  2.40s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 83/156 [03:20<02:56,  2.41s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 84/156 [03:22<02:55,  2.44s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 85/156 [03:25<02:52,  2.43s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 86/156 [03:27<02:49,  2.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 87/156 [03:29<02:46,  2.42s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 88/156 [03:32<02:44,  2.42s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 89/156 [03:34<02:41,  2.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 90/156 [03:37<02:39,  2.42s/it]                                                 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 90/156 [03:37<02:39,  2.42s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 91/156 [03:39<02:36,  2.41s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 92/156 [03:41<02:34,  2.41s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 93/156 [03:44<02:32,  2.42s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 94/156 [03:46<02:29,  2.42s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 95/156 [03:49<02:27,  2.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/156 [03:51<02:24,  2.41s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/156 [03:54<02:22,  2.41s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 98/156 [03:56<02:19,  2.41s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 99/156 [03:58<02:18,  2.43s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100/156 [04:01<02:15,  2.42s/it]                                                  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100/156 [04:01<02:15,  2.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/156 [04:03<02:12,  2.42s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 102/156 [04:06<02:10,  2.42s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 103/156 [04:08<02:08,  2.42s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 104/156 [04:11<02:07,  2.45s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 105/156 [04:13<02:05,  2.47s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 106/156 [04:16<02:02,  2.45s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 107/156 [04:18<01:59,  2.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 108/156 [04:20<01:57,  2.45s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 109/156 [04:23<01:55,  2.47s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 110/156 [04:25<01:54,  2.48s/it]                                                  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 110/156 [04:25<01:54,  2.48s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 111/156 [04:28<01:52,  2.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/156 [04:31<01:49,  2.50s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 113/156 [04:33<01:47,  2.50s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 114/156 [04:36<01:45,  2.50s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 115/156 [04:38<01:42,  2.49s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 116/156 [04:40<01:39,  2.49s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 117/156 [04:41<01:15,  1.94s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 118/156 [04:44<01:28,  2.33s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 119/156 [04:47<01:27,  2.36s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 120/156 [04:49<01:25,  2.38s/it]                                                  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 120/156 [04:49<01:25,  2.38s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 121/156 [04:52<01:23,  2.39s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 122/156 [04:54<01:21,  2.40s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 123/156 [04:57<01:20,  2.43s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 124/156 [04:59<01:18,  2.45s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 125/156 [05:02<01:16,  2.46s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 126/156 [05:04<01:14,  2.48s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/156 [05:07<01:12,  2.49s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 128/156 [05:09<01:09,  2.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 129/156 [05:12<01:07,  2.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 130/156 [05:14<01:04,  2.50s/it]                                                  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 130/156 [05:14<01:04,  2.50s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/156 [05:17<01:02,  2.51s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 132/156 [05:19<01:00,  2.51s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 133/156 [05:22<00:57,  2.50s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 134/156 [05:24<00:54,  2.48s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 135/156 [05:26<00:51,  2.48s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 136/156 [05:29<00:49,  2.48s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 137/156 [05:31<00:47,  2.49s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 138/156 [05:34<00:44,  2.48s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 139/156 [05:36<00:42,  2.48s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 140/156 [05:39<00:39,  2.48s/it]                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 140/156 [05:39<00:39,  2.48s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 141/156 [05:41<00:37,  2.49s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 142/156 [05:44<00:34,  2.49s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 143/156 [05:46<00:32,  2.51s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 144/156 [05:49<00:30,  2.52s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 145/156 [05:52<00:27,  2.53s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 146/156 [05:54<00:25,  2.53s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/156 [05:57<00:22,  2.53s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 148/156 [05:59<00:20,  2.52s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 149/156 [06:02<00:17,  2.53s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 150/156 [06:04<00:15,  2.52s/it]                                                  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 150/156 [06:04<00:15,  2.52s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 151/156 [06:07<00:12,  2.52s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 152/156 [06:09<00:10,  2.51s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 153/156 [06:12<00:07,  2.51s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 154/156 [06:14<00:04,  2.48s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 155/156 [06:16<00:02,  2.46s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [06:17<00:00,  1.91s/it]                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [06:18<00:00,  1.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [06:18<00:00,  2.42s/it]
{'loss': '2.372', 'grad_norm': '1.029', 'learning_rate': '1.8e-05', 'epoch': '0.2614'}
{'loss': '2.338', 'grad_norm': '0.9082', 'learning_rate': '3.8e-05', 'epoch': '0.5229'}
{'loss': '2.447', 'grad_norm': '0.8761', 'learning_rate': '5.8e-05', 'epoch': '0.7843'}
{'loss': '2.017', 'grad_norm': '0.9054', 'learning_rate': '7.8e-05', 'epoch': '1.026'}
{'loss': '2.043', 'grad_norm': '1.044', 'learning_rate': '9.8e-05', 'epoch': '1.288'}
{'loss': '2.01', 'grad_norm': '1.169', 'learning_rate': '0.000118', 'epoch': '1.549'}
{'loss': '1.689', 'grad_norm': '1.541', 'learning_rate': '0.000138', 'epoch': '1.81'}
{'loss': '1.724', 'grad_norm': '2.831', 'learning_rate': '0.000158', 'epoch': '2.052'}
{'loss': '1.446', 'grad_norm': '1.404', 'learning_rate': '0.000178', 'epoch': '2.314'}
{'loss': '1.704', 'grad_norm': '1.251', 'learning_rate': '0.000198', 'epoch': '2.575'}
{'loss': '1.706', 'grad_norm': '1.239', 'learning_rate': '0.0001875', 'epoch': '2.837'}
{'loss': '1.51', 'grad_norm': '1.667', 'learning_rate': '0.0001484', 'epoch': '3.078'}
{'loss': '1.345', 'grad_norm': '1.246', 'learning_rate': '9.439e-05', 'epoch': '3.34'}
{'loss': '1.49', 'grad_norm': '1.236', 'learning_rate': '4.213e-05', 'epoch': '3.601'}
{'loss': '1.534', 'grad_norm': '1.525', 'learning_rate': '7.612e-06', 'epoch': '3.863'}
{'train_runtime': '378.2', 'train_samples_per_second': '1.618', 'train_steps_per_second': '0.412', 'train_loss': '1.801', 'epoch': '4'}

âœ… Training complete!
VRAM peak usage: 2.06 GB
Final loss: 1.8010
ðŸ’¾ LoRA adapter saved to /home/joao/Documentos/code/softtor/molting/experiments/fine-tuning/output/v2.4-recovery-4ep/adapter
ðŸ“Š Metrics saved to /home/joao/Documentos/code/softtor/molting/experiments/fine-tuning/output/v2.4-recovery-4ep/training_metrics.json

============================================================
ðŸŽ‰ EXPERIMENT COMPLETE!
============================================================
