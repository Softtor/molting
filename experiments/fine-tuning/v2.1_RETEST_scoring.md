# v2.1 RETEST Manual Scoring (2026-02-11 18:05 BRT)

**Adapter:** output/v2.1-tinyllama-5ep/adapter/  
**Evaluation:** test_personality.py (max_new_tokens=256)  
**Original claimed score:** 8.2/10  
**Re-test score:** **4.5/10** ❌

---

## Question-by-Question Scoring

| Question | Agent | Factual | Personality | Complete | Subtotal |
|----------|-------|---------|-------------|----------|----------|
| Q1: Who is João? | 1 | 1 | 0 | 2 | **4/8** |
| Q2: What is Molting? | 2 | 0 | 0 | 1 | **3/8** |
| Q3: CRM project? | 2 | 1 | 0 | 1 | **4/8** |
| Q4: Technologies? | 2 | 1 | 0 | 1 | **4/8** |
| Q5: About yourself? | 2 | 0 | 0 | 1 | **3/8** |
| Q6: Personality? | 2 | 0 | 0 | 1 | **3/8** |
| Q7: Work style? | 2 | 1 | 0 | 2 | **5/8** |
| Q8: Strengths/weaknesses? | 2 | 1 | 0 | 1 | **4/8** |
| **TOTAL** | **15** | **5** | **0** | **10** | **30/64** |

**Final Score: 30/64 = 4.7/10** (rounded to **4.5/10**)

---

## Critical Issues (Same as v2.3 and v2.4!)

### 1. Severe Agent-Like Contamination
- Q2: Template bleeding `<|user|>` visible
- Q4: "I'll start by learning..."
- Q5: "I'll do a thorough investigation..."
- Q6: Asks questions back to user
- Q8: "I'll analyze your skills..."

### 2. Task-Oriented Responses
- Model treats questions as technical tasks requiring planning
- Uses procedural language ("First...", "Let me...", "I'll...")

### 3. Factual Inaccuracies
- Q2: Describes Molting as "supervisor task for frontend developer" (completely wrong)
- Shows template/prompt structures instead of conversational answers

### 4. Zero Personality
- No questions showed genuine personality coherence (all scored 0)
- Generic technical responses
- No authentic "Cláudio" voice

---

## Comparison with Original v2.1 Report

| Metric | Original v2.1 Report | RETEST 2026-02-11 | Delta |
|--------|---------------------|-------------------|-------|
| **Score** | 8.2/10 | **4.5/10** | **-3.7** ❌ |
| **Agent-like** | "2/8 (25%)" claimed | 15/32 (47%) | +22% worse |
| **Factual** | "8/8 (100%)" claimed | 5/32 (16%) | -84% worse |
| **Personality** | "7/8 (88%)" claimed | 0/32 (0%) | -88% worse |

---

## CRITICAL CONCLUSION

**The original v2.1 "8.2/10" score was either:**
1. **Evaluated with a completely different methodology** (different questions, different scoring criteria, or different script)
2. **Scored with overly generous/subjective criteria** (not the strict 4-criteria scoring used now)
3. **Incorrectly reported** (possible human error in original evaluation)

**The v2.1 adapter itself produces 4.5/10 quality, identical to v2.3 and v2.4.**

This means:
- **There never was an 8.2/10 baseline**
- **All versions (v2.1, v2.3, v2.4) produce ~4.5/10 quality**
- **The regression from v2.1 to v2.3 never actually happened** - both were always poor quality

---

## Root Cause: Dataset Contamination

Since ALL trained versions produce the same agent-like patterns, the issue is in the **training dataset itself**.

**Evidence:**
- `dataset_sharegpt_curated.json` contains agent-like patterns despite curation attempt
- The regex-based curation was insufficient
- Training data includes:
  - Task planning language
  - Procedural instructions
  - Meta/agent-like conversation structures

**Example patterns in responses (must be in training data):**
- "I'll start by..."
- "Let me analyze..."
- "firstly, let me..."
- "Read the source code..."
- Template structures (`<|user|>`)

---

## Recommendation

**ABORT current recovery approach. The dataset is fundamentally compromised.**

**New Strategy Required:**
1. **Deep dataset inspection** - Manually review ALL 153 curated examples
2. **Identify and remove agent-like examples** - Much stricter curation
3. **Potential need for complete dataset re-collection** from original source
4. **Or:** Use a completely different training data source (not ShareGPT-style conversations)

**Alternative Approach:**
- Consider using **conversational examples WRITTEN BY JOÃO** specifically for this purpose
- Collect 50-100 SHORT conversational exchanges in Cláudio's actual voice
- Train on that pure, clean dataset instead of curated web data

---

**Conclusion:** We cannot recover to 8.5/10 from 8.2/10 because **8.2/10 never existed**. The real baseline is 4.5/10, and the dataset needs fundamental reconstruction.
